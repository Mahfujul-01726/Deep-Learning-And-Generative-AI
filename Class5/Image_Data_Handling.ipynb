{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Loading Images using opencv\n"
      ],
      "metadata": {
        "id": "O6lzekrebI2r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dzcSHrnaj5F",
        "outputId": "d3980c8d-1387-460e-ca31-a0af18c163e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (276, 183, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load image in color mode\n",
        "image = cv2.imread(\"/content/cat.jpg\", cv2.IMREAD_COLOR)\n",
        "\n",
        "# Convert image to RGB format (OpenCV loads images in BGR format)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display image shape\n",
        "print(\"Image shape:\", image_rgb.shape)  # (Height, Width, Channels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using tensorflow**"
      ],
      "metadata": {
        "id": "AP8FKO7HbwKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load image using TensorFlow\n",
        "image = tf.keras.preprocessing.image.load_img(\"/content/cat.jpg\")\n",
        "\n",
        "# Convert image to NumPy array\n",
        "image_np = tf.keras.preprocessing.image.img_to_array(image)\n",
        "\n",
        "print(\"Image shape:\", image_np.shape)  # (Height, Width, Channels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhVkxWnubrcb",
        "outputId": "8bdb2899-3595-488b-eed5-9c7a1e42b88d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (276, 183, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PyTorch**"
      ],
      "metadata": {
        "id": "6JZyrKI8b-YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load image\n",
        "image = Image.open(\"/content/cat.jpg\")\n",
        "\n",
        "# Convert image to PyTorch tensor\n",
        "transform = transforms.ToTensor()\n",
        "image_tensor = transform(image)\n",
        "\n",
        "print(\"Tensor shape:\", image_tensor.shape)  # (Channels, Height, Width)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO4v57vkb5Di",
        "outputId": "cd5618ec-a85b-46ba-fb01-ced3f8a76a35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: torch.Size([3, 276, 183])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Resizing Images using OpenCV"
      ],
      "metadata": {
        "id": "eNdw32a5bXyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image = cv2.resize(image_rgb, (224, 224))  # Resize to 224x224\n",
        "print(\"Resized shape:\", resized_image.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0y0_prgam9N",
        "outputId": "af457367-c545-498f-c40c-d96fb4d00d34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized shape: (224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using TensorFlow**"
      ],
      "metadata": {
        "id": "thtcZPbfcHKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized_image = tf.image.resize(image_np, (224, 224))\n",
        "print(\"Resized shape:\", resized_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeuk6ELnam7K",
        "outputId": "7534d2b0-8d9c-45fa-beeb-91d9db16e726"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized shape: (224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "image_resized = transform(image)\n",
        "print(\"Resized shape:\", resized_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3MYk042am48",
        "outputId": "2d90e2b3-b921-46c0-d3f5-d955bbb73a14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resized shape: (224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Normalizing Images Using OpenCV"
      ],
      "metadata": {
        "id": "MaTeD2N_cl9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_normalized = image_rgb / 255.0  # Normalize to [0,1]\n"
      ],
      "metadata": {
        "id": "5IArr20Eam2E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Tensorflow**"
      ],
      "metadata": {
        "id": "izXojaT3drhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_normalized = tf.keras.applications.vgg16.preprocess_input(image_np)\n"
      ],
      "metadata": {
        "id": "s5ZM8NcQclaz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Pytorch**"
      ],
      "metadata": {
        "id": "PnPNIx8xdz4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "image_normalized = transform(image)\n"
      ],
      "metadata": {
        "id": "VIEHvYR8clYU"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}