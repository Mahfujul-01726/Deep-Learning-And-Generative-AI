# Deep Learning & Generative AI Course Outline
**Total Class 24**

| **Module** | **Class** | **Topics** |
|------------|-----------|------------|
| **Module 1: Introduction to Deep Learning and AI (4 Classes)** | **Class 1** | **Introduction to AI and Machine Learning** |
| | | ● Overview of AI, ML, and DL |
| | | ● Key Concepts and Terminologies |
| | | ● Historical Context and Evolution |
| | | ● Key Concepts: Generative AI, LLM, Vector Database, Hugging Face, LangChain |
| | | ● Importance of Kaggle profile |
| | | ○ Kaggle Competition |
| | | ● The job of DL, LLM, Generative AI |
| | **Class 2** | **Basics of Neural Networks** |
| | | ● Artificial Neurons |
| | | ● Activation Functions: Linear, Sigmoid, Softmax, Tanh, ReLu, Leaky ReLu |
| | | ● Dying ReLu Problem |
| | | ● ANN Architecture |
| | | ● Forward and Backward Propagation |
| | | ● Training Neural Networks with Python |
| | **Class 3** | **Deep Learning Frameworks and Tools** |
| | | ● Introduction to Popular Frameworks: Keras, TensorFlow, PyTorch |
| | | ● Setting up the Environment |
| | | ● Basic Operations |
| | | ● Model Creation with Python |
| | **Class 4** | **Training Deep Learning Models** |
| | | ● Data Import, Preparation, and Preprocessing |
| | | ● Loss Functions and Optimization Algorithms |
| | | ○ Gradient Descent Optimizer |
| | | ○ Variants of Gradient Descents (Momentum, Nesterov Momentum, AdaGrad, RMSProp, Adam, Nadam) |
| | | ● Gradient Problems (Vanishing & Exploding) |
| | | ● Key Concepts of Overfitting, Underfitting, and Bestfitting |
| | | ● Regularization Techniques |
| **Module 2: Computer Vision (8 Classes)** | **Class 5** | **Introduction to Computer Vision** |
| | | ● Overview of Computer Vision Tasks |
| | | ● Image Data Handling |
| | | ● Data Augmentation |
| | **Class 6** | **Convolutional Neural Networks (CNNs)** |
| | | ● CNN Architecture and Components |
| | | ● Convolution and Pooling Layers |
| | | ● Fully Connected Layer |
| | **Class 7** | **Advanced CNN Architectures** |
| | | ● Popular CNN Models (LeNet, AlexNet, VGG, ResNet, Inception) |
| | | ● Transfer Learning |
| | | ● Fine-tuning |
| | **Class 8** | **Object Detection and Localization** |
| | | ● Techniques (R-CNN, Fast R-CNN, Faster R-CNN, YOLO) |
| | | ● Implementation and Applications |
| | **Class 9** | **Semantic Segmentation and Image Segmentation** |
| | | ● Techniques (U-Net, Fully Convolutional Networks) |
| | | ● Practical Examples and Use Cases |
| | | ● Implementation with Python |
| | **Class 10** | **Generative Adversarial Networks (GANs) in Computer Vision** |
| | | ● Introduction to GANs |
| | | ● Architecture |
| | | ● Training of GANs with Python |
| | **Class 11** | **Applications of GANs in Computer Vision** |
| | | ● Image Generation and Transformation |
| | | ● Style Transfer and Super-Resolution |
| | | ● Implementation with Python |
| | **Class 12** | **Computer Vision Projects** |
| | | ● Implementing a Real-World Project |
| | | ● Best Practices and Troubleshooting |
| | | ● Project Name: Automatic Dhaka Traffic Detection using the YOLO Model |
| **Module 3: Natural Language Processing (NLP) (7 Classes)** | **Class 13** | **Introduction to NLP** |
| | | ● Overview of NLP Tasks |
| | | ● Text Preprocessing Techniques |
| | | ● Regex |
| | | ● Implementation with Python |
| | **Class 14** | **Word Embeddings and Representations** |
| | | ● Tf-idf, Word2Vec, GloVe, FastText |
| | | ● Contextual Embeddings (ELMo, BERT) |
| | | ● Implementation with Python |
| | **Class 15** | **Recurrent Neural Networks (RNNs) and Variants** |
| | | ● Basic RNN Architecture |
| | | ● Long Short-Term Memory (LSTM) |
| | | ● Gated Recurrent Unit (GRU) |
| | | ● Implementation with Python |
| | **Class 16** | **Attention Mechanisms and Transformers** |
| | | ● Attention Mechanism |
| | | ● Transformers: Input Embeddings, Positional Encodings, Encoder, Decoder, Output Layer |
| | **Class 17** | **Advanced Transformer Models** |
| | | ● BERT, GPT, T5, and Their Applications |
| | | ● Fine-Tuning Pre-trained Transformers |
| | | ● Evaluate NLP Models |
| | **Class 18** | **Sequence-to-Sequence Models and Applications** |
| | | ● Machine Translation, Text Summarization |
| | | ● Practical Examples |
| | | ● Implementation with Python |
| | **Class 19** | **NLP Projects** |
| | | ● Implementing a Real-World Project |
| | | ● Best Practices and Troubleshooting |
| | | ● Project Name: Word Spelling Correction |
| **Module 4: Generative AI (6 Classes)** | **Class 20** | **Introduction to Generative AI** |
| | | ● Overview of Generative Models |
| | | ● Applications and Use Cases |
| | **Class 21** | **Variational Autoencoders (VAEs)** |
| | | ● VAE Architecture and Training |
| | | ● Applications in Image and Text Generation |
| | | ● Implementation with Python |
| | **Class 22** | **Advanced GAN Techniques** |
| | | ● Variants of GANs (DCGAN, CycleGAN, StyleGAN) |
| | | ● Training Stability and Challenges |
| | | ● Implementation with Python |
| | **Class 23** | **Generative AI in NLP** |
| | | ● Langchain & Hugging Face Introduction |
| | | ● LLM Model Introduce & Fine-Tuning LLM Model (Gemma and LLAMA Models) |
| | | ● Text Generation with LLM Models |
| | | ● Applications in Chatbots and Content Creation |
| | | ● Implementation with Python |
| | **Class 24** | **Generative AI Project** |
| | | ● Project Name: LLM Langchain Project using Vector Database |
